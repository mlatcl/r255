---
title: "R255: Bias, Variance and Fairness: Stochasticity in Decision Making"
edit_url: https://github.com/lawrennd/talks/edit/gh-pages/_r255/bias-variance-and-fairness-stochasticity-in-decision-making.md
blog: 2017-11-15-decision-making.md
blog: 2018-02-06-natural-and-artificial-intelligence.md
blog: 2015-12-04-what-kind-of-ai.md
date: 2023-01-20
published: 2023-01-20
time: "12:30"
week: 0
reveal: bias-variance-and-fairness-stochasticity-in-decision-making.slides.html
transition: None
ipynb: null
layout: lecture
categories:
- notes
---



<!-- Do not edit this file locally. -->
<!---->
<!-- Do not edit this file locally. -->
<!-- Do not edit this file locally. -->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
<!--

-->
<p>to the R255 module on Bi</p>
<p>Papers: Performative Prediction</p>
<p>The NeurIPS Experiment Variance Modelling</p>
<p>English Meaning and Culture Anna Wierzbicka Year: 2006 Chaper 5: Being fair Another Key Anglo Value and Its Cultural Underpinnings</p>
<h2 id="justice-whats-the-right-thing-to-do">Justice: What’s The Right Thing to Do?</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/justice-sandel.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/justice-sandel.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="justice-whats-the-right-thing-to-do-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="https://inverseprobability.com/talks/./slides/diagrams//philosophy/justice-whats-the-right-thing-to-do.jpg" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="justice-whats-the-right-thing-to-do-magnify" class="magnify" onclick="magnifyFigure(&#39;justice-whats-the-right-thing-to-do&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="justice-whats-the-right-thing-to-do-caption" class="caption-frame">
<p>Figure: Sandel’s book looks at how to do the right thing with a context of moreal philosophy. <span class="citation" data-cites="Sandel-justice10">Sandel (2010)</span></p>
</div>
</div>
<p>In the book “Justice: What’s The Right Thing to Do?” <span class="citation" data-cites="Sandel-justice10">(Sandel, 2010)</span> Michael Sandel aims to help us answer questions about how to do the right thing by giving some context and background in moral philosophy. Sandel is a philosopher based at Harvard University who is reknowned for his popular treatments of the subject. He starts by illustrating decision making through the <a href="https://en.wikipedia.org/wiki/Trolley_problem">‘trolley’ problem</a>.</p>
<h2 id="the-trolley-problem">The Trolley Problem</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/trolley-switch.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/trolley-switch.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="trolley-problem-original-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="negate" src="https://inverseprobability.com/talks/./slides/diagrams//ai/Trolley_1.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="trolley-problem-original-magnify" class="magnify" onclick="magnifyFigure(&#39;trolley-problem-original&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="trolley-problem-original-caption" class="caption-frame">
<p>Figure: The trolley problem in its original form.</p>
</div>
</div>
<h2 id="the-push-and-the-trolley">The Push and the Trolley</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/trolley-push.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/trolley-push.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="the-trolley-problem-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="negate" src="https://inverseprobability.com/talks/./slides/diagrams//ai/trolley2.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="the-trolley-problem-magnify" class="magnify" onclick="magnifyFigure(&#39;the-trolley-problem&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="the-trolley-problem-caption" class="caption-frame">
<p>Figure: The trolley problem.</p>
</div>
</div>
<h2 id="what-is-machine-learning">What is Machine Learning?</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/what-is-ml-2.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/what-is-ml-2.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>Machine learning allows us to extract knowledge from data to form a prediction.</p>
<p><span class="math display">\[\text{data} + \text{model} \stackrel{\text{compute}}{\rightarrow} \text{prediction}\]</span></p>
<p>A machine learning prediction is made by combining a model with data to form the prediction. The manner in which this is done gives us the machine learning <em>algorithm</em>.</p>
<p>Machine learning models are <em>mathematical models</em> which make weak assumptions about data, e.g. smoothness assumptions. By combining these assumptions with the data, we observe we can interpolate between data points or, occasionally, extrapolate into the future.</p>
<p>Machine learning is a technology which strongly overlaps with the methodology of statistics. From a historical/philosophical view point, machine learning differs from statistics in that the focus in the machine learning community has been primarily on accuracy of prediction, whereas the focus in statistics is typically on the interpretability of a model and/or validating a hypothesis through data collection.</p>
<p>The rapid increase in the availability of compute and data has led to the increased prominence of machine learning. This prominence is surfacing in two different but overlapping domains: data science and artificial intelligence.</p>
<h2 id="from-model-to-decision">From Model to Decision</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/what-is-ml-end-to-end.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/what-is-ml-end-to-end.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The real challenge, however, is end-to-end decision making. Taking information from the environment and using it to drive decision making to achieve goals.</p>
<h2 id="prospect-theory">Prospect Theory</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/bias-towards-variance.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/bias-towards-variance.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<ul>
<li>Daniel Kahneman’s Nobel Memorial Prize in Economics was awarded for the idea of <em>prospect theory</em>.</li>
<li>Kahneman describes the theory and its background in his book, “Thinking Fast and Slow” <span class="citation" data-cites="Kahneman-fastslow11">(<strong>Kahneman-fastslow11?</strong>)</span>.</li>
<li>Empirical theory about how people are responsive to change in circumstance, not absolute circumstance.</li>
</ul>
<h2 id="subjective-utility">Subjective Utility</h2>
<ul>
<li>Bentham’s ideas focussed around the idea of a global utility.</li>
<li>Natural selection insists there must be <em>variation</em> in the population</li>
<li>Without variation, there is no separation between effective and ineffective strategies.</li>
</ul>
<h2 id="a-cognitive-bias-towards-variance">A Cognitive Bias towards Variance</h2>
<ul>
<li>Kahneman explores our tendency to produce overcomplicated explanations</li>
<li>Prediction is <span class="math display">\[ \text{model} + \text{data} \rightarrow \text{prediction}\]</span></li>
<li>Models fail as overly simple or overly complex</li>
</ul>
<h2 id="bias-vs-variance">Bias vs Variance</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/bias-variance-in-ml.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/bias-variance-in-ml.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<ul>
<li>‘bias variance dilemma’ <span class="citation" data-cites="Geman-biasvariance92">(<strong>Geman-biasvariance92?</strong>)</span></li>
<li>Decompose errors as
<ol type="1">
<li>due to oversimplification (the bias error) and</li>
<li>those due to insufficient data to underpin a complex model (variance error).</li>
</ol></li>
</ul>
<h2 id="in-machine-learning">In Machine Learning</h2>
<ul>
<li>Two approaches
<ul>
<li>Use simpler models (better consistency and generalization)</li>
<li>Use more complex models and average.</li>
</ul></li>
</ul>
<h2 id="bias-vs-variance-error-plots">Bias vs Variance Error Plots</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/bias-variance-plots.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/bias-variance-plots.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>Helper function for sampling data from two different classes.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span></code></pre></div>
<p>Helper function for plotting the decision boundary of the SVM.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> urllib.request</span></code></pre></div>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>urllib.request.urlretrieve(<span class="st">&#39;https://raw.githubusercontent.com/lawrennd/talks/gh-pages/mlai.py&#39;</span>,<span class="st">&#39;mlai.py&#39;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>font <span class="op">=</span> {<span class="st">&#39;family&#39;</span> : <span class="st">&#39;sans&#39;</span>,</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;weight&#39;</span> : <span class="st">&#39;bold&#39;</span>,</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;size&#39;</span>   : <span class="dv">22</span>}</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>matplotlib.rc(<span class="st">&#39;font&#39;</span>, <span class="op">**</span>font)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code></pre></div>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> svm</span></code></pre></div>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an instance of SVM and fit the data. </span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>C <span class="op">=</span> <span class="fl">100.0</span>  <span class="co"># SVM regularization parameter</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>gammas <span class="op">=</span> [<span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="dv">1</span>]</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>per_class<span class="op">=</span><span class="dv">30</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>num_samps <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Set-up 2x2 grid for plotting.</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">4</span>, figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">3</span>))</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>xlim<span class="op">=</span><span class="va">None</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>ylim<span class="op">=</span><span class="va">None</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> samp <span class="kw">in</span> <span class="bu">range</span>(num_samps):</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    X, y<span class="op">=</span>create_data(per_class)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    models <span class="op">=</span> []</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    titles <span class="op">=</span> []</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> gamma <span class="kw">in</span> gammas:</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>        models.append(svm.SVC(kernel<span class="op">=</span><span class="st">&#39;rbf&#39;</span>, gamma<span class="op">=</span>gamma, C<span class="op">=</span>C))</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>        titles.append(<span class="st">&#39;$\gamma=</span><span class="sc">{}</span><span class="st">$&#39;</span>.<span class="bu">format</span>(gamma))</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    models <span class="op">=</span> (cl.fit(X, y) <span class="cf">for</span> cl <span class="kw">in</span> models)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    xlim, ylim <span class="op">=</span> decision_boundary_plot(models, X, y, </span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>                           axs<span class="op">=</span>ax, </span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>                           filename<span class="op">=</span><span class="st">&#39;bias-variance</span><span class="sc">{samp:0&gt;3}</span><span class="st">.svg&#39;</span>.<span class="bu">format</span>(samp<span class="op">=</span>samp), </span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>                           directory<span class="op">=</span><span class="st">&#39;./ml&#39;</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>                           titles<span class="op">=</span>titles,</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>                          xlim<span class="op">=</span>xlim,</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>                          ylim<span class="op">=</span>ylim)</span></code></pre></div>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install pods</span></code></pre></div>
<!---->
<div class="figure">
<div id="bias-variance-errors-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://inverseprobability.com/talks/./slides/diagrams//ml/bias-variance000.png" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<div class="centered" style="">
<img class="" src="https://inverseprobability.com/talks/./slides/diagrams//ml/bias-variance010.png" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="bias-variance-errors-magnify" class="magnify" onclick="magnifyFigure(&#39;bias-variance-errors&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="bias-variance-errors-caption" class="caption-frame">
<p>Figure: In each figure the simpler model is on the left, and the more complex model is on the right. Each fit is done to a different version of the data set. The simpler model is more consistent in its errors (bias error), whereas the more complex model is varying in its errors (variance error).</p>
</div>
</div>
<h2 id="decision-making-and-bias-variance">Decision Making and Bias-Variance</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/bias-variance-in-ml.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/bias-variance-in-ml.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<ul>
<li>In a population we should prefer variance-errors.
<ul>
<li>Bias errors lead to consistent, decsion making.</li>
<li>Consistently wrong!</li>
</ul></li>
<li>Variance errors can also be averaged e.g. <a href="https://en.wikipedia.org/wiki/Bootstrap_aggregating">bagging</a> and <a href="https://en.wikipedia.org/wiki/Boosting_(machine_learning)">boosting</a> <span class="citation" data-cites="Breiman-bagging96">(<strong>Breiman-bagging96?</strong>)</span></li>
</ul>
<h2 id="rational-behaviour">Rational Behaviour</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/bias-variance-rational.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/bias-variance-rational.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<ul>
<li>Sustain a variety of approaches to life.</li>
<li>Complex explanations such as half-time football punditry.</li>
<li>Also clinical experts <span class="citation" data-cites="Meehl-clinicalstatistical54">(Meehl, 1954)</span>. Meehl suggested they ‘try to be clever and think outside the box.’</li>
</ul>
<h2 id="one-correct-solution">One Correct Solution</h2>
<ul>
<li>Artificial Selection and Eugenics.</li>
<li>OK for race horses, greyhounds, crops, sheep and cows</li>
<li>Not OK for the human race.</li>
</ul>
<h2 id="one-correct-solution-1">One Correct Solution</h2>
<ul>
<li>Flawed understanding of science</li>
<li>Animals in a species become too specialised then they may not be able to respond to changing circumstances.
<ul>
<li>Think of cheetahs and eagles vs rats and pigeons.</li>
</ul></li>
</ul>
<h2 id="similar-ideas-socially">Similar Ideas Socially</h2>
<blockquote>
<p>I may not agree with many people’s subjective approach to life, I may even believe it to be severely sub-optimal. But I should not presume to know better, even if prior experience shows that my own ‘way of being’ is effective.</p>
<p>Variation is vitally important for robustness. There may be future circumstances where my approaches fail utterly, and other ways of being are better.</p>
</blockquote>
<h2 id="a-universal-utility">A Universal Utility</h2>
<ul>
<li>Quality of our individual subjective utilities measured by effectiveness.</li>
<li>But it is survival of entire species that dominates long term.</li>
<li>A universal utility by which we are judged is difficult to define.</li>
</ul>
<h2 id="the-real-ethical-dilemma">The Real Ethical Dilemma</h2>
<ul>
<li>Trolley Problem is an oversimplification.</li>
<li>Driverless cars:
<ul>
<li>introduce driverless cars and bring about a 90% reduction in deaths</li>
<li>What if remaining deaths are all cyclists?</li>
</ul></li>
</ul>
<h2 id="uncertainty-the-tyger-that-burns-bright">Uncertainty: The Tyger that Burns Bright</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/uncertainty-and-absolutism.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_philosophy/includes/uncertainty-and-absolutism.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<ul>
<li>Non-survival of the non-fit</li>
<li>The marvel of evolution is its responsiveness.</li>
<li>Utility function evolves socially and in our environment.</li>
</ul>
<p>(<a href="https://en.wikipedia.org/wiki/Survival_of_the_fittest">“survival of the fittest”</a> is due to <a href="https://en.wikipedia.org/wiki/Herbert_Spencer">Herbert Spencer</a>)</p>
<h2 id="absolute-policies">Absolute Policies</h2>
<ul>
<li>There is only one absolute policy we should follow.</li>
</ul>
<blockquote>
<p>There will be single absolute policy that should be followed slavishly in all circumstances</p>
</blockquote>
<h2 id="george-box">George Box</h2>
<blockquote>
<p>Since all models are wrong the scientist must be alert to what is importantly wrong. It is inappropriate to be concerned about mice when there are tigers abroad.</p>
<p>George E. P. Box <span class="citation" data-cites="Box-science76">(Box, 1976)</span></p>
</blockquote>
<h2 id="tigers-and-trolleys">Tigers and Trolleys</h2>
<ul>
<li>A simple switch in the points, is deterministic/mechanistic</li>
</ul>
<div class="figure">
<div id="trolley-problem-1-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="negate" src="https://inverseprobability.com/talks/./slides/diagrams//ai/Trolley_1.jpg" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="trolley-problem-1-magnify" class="magnify" onclick="magnifyFigure(&#39;trolley-problem-1&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="trolley-problem-1-caption" class="caption-frame">
<p>Figure: The original trolley problem. The decision is deterministic.</p>
</div>
</div>
<ul>
<li>The second example is largely contrived, and riddled with uncertainty.</li>
</ul>
<div class="figure">
<div id="trolley-problem-2-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="negate" src="https://inverseprobability.com/talks/./slides/diagrams//ai/trolley2.jpg" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="trolley-problem-2-magnify" class="magnify" onclick="magnifyFigure(&#39;trolley-problem-2&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="trolley-problem-2-caption" class="caption-frame">
<p>Figure: In the situation where you push an overweight gentleman, the decision is riddled with uncertainty. Doubt inevitably creeps in.</p>
</div>
</div>
<h2 id="thanks">Thanks!</h2>
<p>For more information on these subjects and more you might want to check the following resources.</p>
<ul>
<li>twitter: <a href="https://twitter.com/lawrennd">@lawrennd</a></li>
<li>podcast: <a href="http://thetalkingmachines.com">The Talking Machines</a></li>
<li>newspaper: <a href="http://www.theguardian.com/profile/neil-lawrence">Guardian Profile Page</a></li>
<li>blog: <a href="http://inverseprobability.com/blog.html">http://inverseprobability.com</a></li>
</ul>
<h1 class="unnumbered" id="references">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-Box-science76" class="csl-entry" role="doc-biblioentry">
Box, G.E.P., 1976. Science and statistics. Journal of the American Statistical Association 71, 791–799.
</div>
<div id="ref-Meehl-clinicalstatistical54" class="csl-entry" role="doc-biblioentry">
Meehl, P.E., 1954. Clinical versus statistical prediction: A theoretical analysis and a review of the evidence.
</div>
<div id="ref-Sandel-justice10" class="csl-entry" role="doc-biblioentry">
Sandel, M., 2010. Justice: What’s the right thing to do?
</div>
</div>

