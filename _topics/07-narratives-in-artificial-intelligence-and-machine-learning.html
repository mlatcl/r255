---
title: "R255: Narratives in Artificial Intelligence and Machine
Learning"
venue: "William Gates Building"
abstract: "<p>In this talk we will explore a fundamental limitation of
human intelligence which, we argue, makes cultural communication vital
in sharing ideas. This will motivate the importance of narrative in
setting cultural agenda.</p>"
author:
- given: Neil D.
  family: Lawrence
  url: http://inverseprobability.com
  institute: University of Cambridge
  twitter: lawrennd
  gscholar: r3SJcvoAAAAJ
  orcid: 
edit_url: https://github.com/mlatcl/r255/edit/gh-pages/_lamd/narratives-in-artificial-intelligence-and-machine-learning.md
blog: 2017-01-12-data-readiness-levels.md
blog: 2015-12-04-what-kind-of-ai.md
date: 2024-01-19
published: 2024-01-19
featured_image: slides/diagrams/ai/the-diving-bell-and-the-butterfly.jpg
reveal: 07-narratives-in-artificial-intelligence-and-machine-learning.slides.html
transition: None
ipynb: 07-narratives-in-artificial-intelligence-and-machine-learning.ipynb
pptx: 07-narratives-in-artificial-intelligence-and-machine-learning.pptx
layout: topic
categories:
- notes
---



<!-- Do not edit this file locally. -->
<!---->
<!-- Do not edit this file locally. -->
<!-- Do not edit this file locally. -->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
<!--

-->
<h2 id="overview">Overview</h2>
<p>In this topic we will explore the relationship between narrative and
the development of machine learning and AI solutions. The course will be
taught in collaboration with Nichole Ravindran and Alessandro
Trevisan.</p>
<p>How do machine-learning researchers understand the narratives,
philosophies, and theories surrounding the present-day understanding of
AGI? How could the Fynesse Framework be employed to find more near-term
datasets, themes, and problems to study?</p>
<p>ML Problem: If the AI narratives currently being promoted are seen in
some parts of the machine learning community as too speculative or
longtermfocused, then how does one extrapolate more near-term problems
and themes from them to study within the machine learning community?</p>
<p>We will look at look at different papers related to narratives,
philosophies and theories related to artificial intelligence and
determine if there are other meaningful ways of identifying problems,
themes, and datasets curated based on them.</p>
<p>The first paper set is:</p>
<ol type="1">
<li><a
href="https://arxiv.org/abs/2401.02843#:~:text=In%20the%20largest%20survey%20of,achieving%20several%20milestones%20by%202028%2C">Thousands
of AI Authors on the Future of AI</a> by Katja Grace, Harlan Stewart,
Julia Fabienne Sandkühler, Stephen Thomas, Ben Weinstein-Raun, and Jan
Brauner.</li>
</ol>
<p>Here’s a list of other papers that could be chosen for other
sessions, or if there’s something you’d like to suggest, let us
know!</p>
<ol type="1">
<li><p><a
href="https://www.cambridge.org/core/books/machine-ethics/asimovs-laws-ofrobotics/842C02FFA647B8150161E3836435F9B2">Asimov’s
Laws of Robotics - Implications for Information Technology</a> (Chapter
15 of Machine Ethics 2011; Cambridge Core) - Roger Clark</p></li>
<li><p><a
href="https://link.springer.com/article/10.1007/s10676-007-9138-2">AI
Armageddon and the Three Laws of Robotics</a> (Ethics and Information
Technology, Springer 2007) - Lee McCauley</p></li>
<li><p><a
href="https://openyls.law.yale.edu/handle/20.500.13051/4697">The Three
Laws of Robotics in the Age of Big Data</a> (2016 Sidley Austin
Distinguished Lecture on Big Data Law and Policy; Ohio State Law
Journal) - Jack M. Balkin</p></li>
<li><p><a
href="https://www.cambridge.org/core/books/machine-ethics/unacceptabilityof-asimovs-three-laws-of-robotics-as-a-basis-for-machineethics/D58C8BAD402DF52AD2785C17A68431EB">The
Unacceptability of Asimov’s Three Laws of Robotics as a Basis for
Machine Ethics</a> (Chapter 16 of Machine Ethics 2011; Cambridge Core)
Susan Leigh Anderson</p></li>
<li><p><a
href="https://dl.acm.org/doi/10.1145/3313831.3376275">Monsters,
Metaphors, and Machine Learning</a> - (Proceedings of the 2020 CHI
Conference on Human Factors in Computing Systems; April 23, 2020) -
Graham Dove and Anne-Laure Fayard</p></li>
<li><p><a
href="https://www.cambridge.org/core/journals/philosophy-ofscience/article/laplaces-demon-and-the-adventures-of-hisapprentices/5A284E42DC95C284C318AEC0B330063B">Laplace’s
Demon and the Adventures of His Apprentices</a> (Cambridge Core,
Philosophy of Science Journal, Jan. 1, 2022) - Roman Frigg, Seamus
Bradley, Hailiang Du and Leonard A Smith</p></li>
<li><p><a
href="https://direct.mit.edu/books/oamonograph/5093/chapter/3042674/Studying-Computer-Scientists">Studying
Computer Scientists</a> (Chapter 1 of The Constitution of Algorithms;
MIT Press, 2020) - Florian Jaton</p></li>
<li><p><a
href="https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-listof-lethalities">AGI
Ruin: A List of Lethalities</a> (2022 MIRI Alignment Discussion;
Blogpost, LessWrong, June 5, 2022) - Eliezer Yudkowsky</p></li>
<li><p><a
href="https://slatestarcodex.com/2014/07/30/meditations-on-moloch/">Meditations
on Moloch</a> (Reflective Essay written by Scott Alexander on Slate Star
Codex, July <span class="math inline">\(30^{\text {th }}\)</span> 2014;
This essay was something shared during an Effective Altruism course I
took as an expression of potentially understanding advanced AI; This
concept is being discussed more recently now.)</p></li>
<li><p><a
href="https://academic.oup.com/edited-volume/34287/chapter/290654580">The
Artificial Intelligence of the Ethics of Artificial Intelligence - An
Introductory Overview for Law and Regulations</a> (Chapter 1 of The
Oxford Handbook of Ethics of AI, 2020) - Edited by Markus D. Dubber,
Frank Pasquale, and Sunit Das</p></li>
<li><p><a href="https://arxiv.org/abs/2303.07103">Could a Large Language
Model be Conscious?</a> (arXiv; April 29, 2023)David J.
Chalmers</p></li>
<li><p><a
href="https://link.springer.com/chapter/10.1007/978-3-319-96448-5_14">Do
Machine-Learning Machines Learn</a> (Conference Paper in Philosophy and
Theory of Artificial Intelligence 2017; SAPERE Vol. 44; August 29, 2018)
- Selmer Bringsjord, Naveen Sundar Govindarajulu, Shreya Banerjee, and
John Hummel</p></li>
<li><p><a
href="https://link.springer.com/chapter/10.1007/978-3-031-09153-7_18">AI
Risk Skepticism</a> (Conference Paper in Philosophy and Theory of
Artificial Intelligence 2021; SAPERE Vol. 63; November 15, 2022) - Roman
V. Yampolskiy</p></li>
<li><p><a
href="https://link.springer.com/chapter/10.1007/978-3-031-09153-7_5">Toward
Out-of-Distribution Generalization Through Inductive Biases</a>
(Conference Paper in Philosophy and Theory of Artificial Intelligence
2021; SAPERE Vol. 63; November 15, 2022) - Caterina Moruzzi</p></li>
<li><p><a
href="https://onlinelibrary.wiley.com/doi/full/10.1111/17585899.12718">The
Vulnerability World Hypothesis</a> (Global Policy Vol. 10; November
2019) - Nick Bostrom</p></li>
</ol>
<p>The presentation for each paper will be in the form of an 800 word
summary that captures the main message of the work and sets it against
the context of the wider discussion we will set up in this first
session.</p>
<h2 id="the-diving-bell-and-the-butterfly">The Diving Bell and the
Butterfly</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/the-diving-bell-butterfly.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/the-diving-bell-butterfly.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="diving-bell-and-butterfly-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/r255/./slides/diagrams//ai/the-diving-bell-and-the-butterfly.jpg" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="diving-bell-and-butterfly-magnify" class="magnify"
onclick="magnifyFigure(&#39;diving-bell-and-butterfly&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="diving-bell-and-butterfly-caption" class="caption-frame">
<p>Figure: The Diving Bell and the Buttefly is the autobiography of Jean
Dominique Bauby.</p>
</div>
</div>
<p><a
href="https://www.penguinrandomhouse.com/books/9616/the-diving-bell-and-the-butterfly-by-jean-dominique-bauby/">The
Diving Bell and the Butterfly</a> is the autobiography of Jean Dominique
Bauby. Jean Dominique was the editor of the French Elle magazine, in
1995 at the age of 43, he suffered a major stroke. The stroke paralyzed
him and rendered him speechless. He was only able to blink his left
eyelid, he became a sufferer of locked in syndrome.</p>
<div class="figure">
<div id="jean-dominique-bauby-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/r255/./slides/diagrams//ai/Jean-Dominique_Bauby.jpg" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="jean-dominique-bauby-magnify" class="magnify"
onclick="magnifyFigure(&#39;jean-dominique-bauby&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="jean-dominique-bauby-caption" class="caption-frame">
<p>Figure: Jean Dominique Bauby was the Editor in Chief of the French
Elle Magazine, he suffered a stroke that destroyed his brainstem,
leaving him only capable of moving one eye. Jean Dominique became a
victim of locked in syndrome.</p>
</div>
</div>
<p>Incredibly, Jean Dominique wrote his book after he became locked in.
It took him 10 months of four hours a day to write the book. Each word
took two minutes to write.</p>
<p>The idea behind embodiment factors is that we are all in that
situation. While not as extreme as for Bauby, we all have somewhat of a
locked in intelligence.</p>
<h2 id="embodiment-factors">Embodiment Factors</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/embodiment-factors-tedx.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/embodiment-factors-tedx.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="embodiment-factors-table-figure" class="figure-frame">
<table>
<tr>
<td>
</td>
<td align="center">
<object class="svgplot " data="https://mlatcl.github.io/r255/./slides/diagrams//computer.svg" width="100%" style=" ">
</object>
</td>
<td align="center">
<object class="svgplot " data="https://mlatcl.github.io/r255/./slides/diagrams//human.svg" width="100%" style=" ">
</object>
</td>
<td align="center">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/r255/./slides/diagrams//ai/Jean-Dominique_Bauby.jpg" width="150%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
<tr>
<td>
bits/min
</td>
<td align="center">
billions
</td>
<td align="center">
2000
</td>
<td align="center">
6
</td>
</tr>
<tr>
<td>
billion<br>calculations/s
</td>
<td align="center">
~100
</td>
<td align="center">
a billion
</td>
<td align="center">
a billion
</td>
</tr>
<tr>
<td>
embodiment
</td>
<td align="center">
20 minutes
</td>
<td align="center">
5 billion years
</td>
<td align="center">
15 trillion years
</td>
</tr>
</table>
</div>
<div id="embodiment-factors-table-magnify" class="magnify"
onclick="magnifyFigure(&#39;embodiment-factors-table&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="embodiment-factors-table-caption" class="caption-frame">
<p>Figure: Embodiment factors are the ratio between our ability to
compute and our ability to communicate. Jean Dominique Bauby suffered
from locked-in syndrome. The embodiment factors show that relative to
the machine we are also locked in. In the table we represent embodiment
as the length of time it would take to communicate one second’s worth of
computation. For computers it is a matter of minutes, but for a human,
whether locked in or not, it is a matter of many millions of years.</p>
</div>
</div>
<p>Let me explain what I mean. Claude Shannon introduced a mathematical
concept of information for the purposes of understanding telephone
exchanges.</p>
<p>Information has many meanings, but mathematically, Shannon defined a
bit of information to be the amount of information you get from tossing
a coin.</p>
<p>If I toss a coin, and look at it, I know the answer. You don’t. But
if I now tell you the answer I communicate to you 1 bit of information.
Shannon defined this as the fundamental unit of information.</p>
<p>If I toss the coin twice, and tell you the result of both tosses, I
give you two bits of information. Information is additive.</p>
<p>Shannon also estimated the average information associated with the
English language. He estimated that the average information in any word
is 12 bits, equivalent to twelve coin tosses.</p>
<p>So every two minutes Bauby was able to communicate 12 bits, or six
bits per minute.</p>
<p>This is the information transfer rate he was limited to, the rate at
which he could communicate.</p>
<p>Compare this to me, talking now. The average speaker for TEDX speaks
around 160 words per minute. That’s 320 times faster than Bauby or
around a 2000 bits per minute. 2000 coin tosses per minute.</p>
<p>But, just think how much thought Bauby was putting into every
sentence. Imagine how carefully chosen each of his words was. Because he
was communication constrained he could put more thought into each of his
words. Into thinking about his audience.</p>
<p>So, his intelligence became locked in. He thinks as fast as any of
us, but can communicate slower. Like the tree falling in the woods with
no one there to hear it, his intelligence is embedded inside him.</p>
<p>Two thousand coin tosses per minute sounds pretty impressive, but
this talk is not just about us, it’s about our computers, and the type
of intelligence we are creating within them.</p>
<p>So how does two thousand compare to our digital companions? When
computers talk to each other, they do so with billions of coin tosses
per minute.</p>
<p>Let’s imagine for a moment, that instead of talking about
communication of information, we are actually talking about money. Bauby
would have 6 dollars. I would have 2000 dollars, and my computer has
billions of dollars.</p>
<p>The internet has interconnected computers and equipped them with
extremely high transfer rates.</p>
<p>However, by our very best estimates, computers actually think slower
than us.</p>
<p>How can that be? You might ask, computers calculate much faster than
me. That’s true, but underlying your conscious thoughts there are a lot
of calculations going on.</p>
<p>Each thought involves many thousands, millions or billions of
calculations. How many exactly, we don’t know yet, because we don’t know
how the brain turns calculations into thoughts.</p>
<p>Our best estimates suggest that to simulate your brain a computer
would have to be as large as the UK Met Office machine here in Exeter.
That’s a 250 million pound machine, the fastest in the UK. It can do 16
billion billon calculations per second.</p>
<p>It simulates the weather across the word every day, that’s how much
power we think we need to simulate our brains.</p>
<p>So, in terms of our computational power we are extraordinary, but in
terms of our ability to explain ourselves, just like Bauby, we are
locked in.</p>
<p>For a typical computer, to communicate everything it computes in one
second, it would only take it a couple of minutes. For us to do the same
would take 15 billion years.</p>
<p>If intelligence is fundamentally about processing and sharing of
information. This gives us a fundamental constraint on human
intelligence that dictates its nature.</p>
<p>I call this ratio between the time it takes to compute something, and
the time it takes to say it, the embodiment factor <span
class="citation" data-cites="Lawrence:embodiment17">(Lawrence,
2017)</span>. Because it reflects how embodied our cognition is.</p>
<p>If it takes you two minutes to say the thing you have thought in a
second, then you are a computer. If it takes you 15 billion years, then
you are a human.</p>
<h2 id="human-communication">Human Communication</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/conversation.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/conversation.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>For human conversation to work, we require an internal model of who
we are speaking to. We model each other, and combine our sense of who
they are, who they think we are, and what has been said. This is our
approach to dealing with the limited bandwidth connection we have.
Empathy and understanding of intent. Mental dispositional concepts are
used to augment our limited communication bandwidth.</p>
<p>Fritz Heider referred to the important point of a conversation as
being that they are happenings that are “<em>psychologically
represented</em> in each of the participants” (his emphasis) <span
class="citation" data-cites="Heider:interpersonal58">(Heider,
1958)</span>.</p>
<h3 id="bandwidth-constrained-conversations">Bandwidth Constrained
Conversations</h3>
<div class="figure">
<div id="anne-bob-conversation-civil-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/r255/./slides/diagrams//anne-bob-conversation006.svg" width="70%" style=" ">
</object>
</div>
<div id="anne-bob-conversation-civil-magnify" class="magnify"
onclick="magnifyFigure(&#39;anne-bob-conversation-civil&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="anne-bob-conversation-civil-caption" class="caption-frame">
<p>Figure: Conversation relies on internal models of other
individuals.</p>
</div>
</div>
<div class="figure">
<div id="anne-bob-conversation-argument-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/r255/./slides/diagrams//anne-bob-conversation007.svg" width="70%" style=" ">
</object>
</div>
<div id="anne-bob-conversation-argument-magnify" class="magnify"
onclick="magnifyFigure(&#39;anne-bob-conversation-argument&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="anne-bob-conversation-argument-caption" class="caption-frame">
<p>Figure: Misunderstanding of context and who we are talking to leads
to arguments.</p>
</div>
</div>
<p>Embodiment factors imply that, in our communication between humans,
what is <em>not</em> said is, perhaps, more important than what is said.
To communicate with each other we need to have a model of who each of us
are.</p>
<p>To aid this, in society, we are required to perform roles. Whether as
a parent, a teacher, an employee or a boss. Each of these roles requires
that we conform to certain standards of behaviour to facilitate
communication between ourselves.</p>
<p>Control of self is vitally important to these communications.</p>
<p>The high availability of data available to humans undermines
human-to-human communication channels by providing new routes to
undermining our control of self.</p>
<h3 id="a-six-word-novel">A Six Word Novel</h3>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/baby-shoes.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/baby-shoes.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="classic-baby-shoes-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/r255/./slides/diagrams//Classic_baby_shoes.jpg" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="classic-baby-shoes-magnify" class="magnify"
onclick="magnifyFigure(&#39;classic-baby-shoes&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="classic-baby-shoes-caption" class="caption-frame">
<p>Figure: Consider the six-word novel, apocryphally credited to Ernest
Hemingway, “For sale: baby shoes, never worn”. To understand what that
means to a human, you need a great deal of additional context. Context
that is not directly accessible to a machine that has not got both the
evolved and contextual understanding of our own condition to realize
both the implication of the advert and what that implication means
emotionally to the previous owner.</p>
</div>
</div>
<p>But this is a very different kind of intelligence than ours. A
computer cannot understand the depth of the Ernest Hemingway’s
apocryphal six-word novel: “For Sale, Baby Shoes, Never worn”, because
it isn’t equipped with that ability to model the complexity of humanity
that underlies that statement.</p>
<h1 id="evolved-relationship-with-information">Evolved Relationship with
Information</h1>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_data-science/includes/evolved-relationship.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/evolved-relationship.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The high bandwidth of computers has resulted in a close relationship
between the computer and data. Large amounts of information can flow
between the two. The degree to which the computer is mediating our
relationship with data means that we should consider it an
intermediary.</p>
<p>Originally our low bandwidth relationship with data was affected by
two characteristics. Firstly, our tendency to over-interpret driven by
our need to extract as much knowledge from our low bandwidth information
channel as possible. Secondly, by our improved understanding of the
domain of <em>mathematical</em> statistics and how our cognitive biases
can mislead us.</p>
<p>With this new set up there is a potential for assimilating far more
information via the computer, but the computer can present this to us in
various ways. If its motives are not aligned with ours then it can
misrepresent the information. This needn’t be nefarious it can be simply
because of the computer pursuing a different objective from us. For
example, if the computer is aiming to maximize our interaction time that
may be a different objective from ours which may be to summarize
information in a representative manner in the <em>shortest</em> possible
length of time.</p>
<p>For example, for me, it was a common experience to pick up my
telephone with the intention of checking when my next appointment was,
but to soon find myself distracted by another application on the phone
and end up reading something on the internet. By the time I’d finished
reading, I would often have forgotten the reason I picked up my phone in
the first place.</p>
<p>There are great benefits to be had from the huge amount of
information we can unlock from this evolved relationship between us and
data. In biology, large scale data sharing has been driven by a
revolution in genomic, transcriptomic and epigenomic measurement. The
improved inferences that can be drawn through summarizing data by
computer have fundamentally changed the nature of biological science,
now this phenomenon is also influencing us in our daily lives as data
measured by <em>happenstance</em> is increasingly used to characterize
us.</p>
<p>Better mediation of this flow requires a better understanding of
human-computer interaction. This in turn involves understanding our own
intelligence better, what its cognitive biases are and how these might
mislead us.</p>
<p>For further thoughts see Guardian article on <a
href="https://www.theguardian.com/media-network/2015/jul/23/data-driven-economy-marketing">marketing
in the internet era</a> from 2015.</p>
<p>You can also check my blog post on <a
href="http://inverseprobability.com/2015/12/04/what-kind-of-ai">System
Zero</a>. This was also written in 2015.</p>
<h2 id="new-flow-of-information">New Flow of Information</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_data-science/includes/new-flow-of-information.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/new-flow-of-information.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>Classically the field of statistics focused on mediating the
relationship between the machine and the human. Our limited bandwidth of
communication means we tend to over-interpret the limited information
that we are given, in the extreme we assign motives and desires to
inanimate objects (a process known as anthropomorphizing). Much of
mathematical statistics was developed to help temper this tendency and
understand when we are valid in drawing conclusions from data.</p>
<div class="figure">
<div id="new-flow-of-information-3-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/r255/./slides/diagrams//data-science/new-flow-of-information003.svg" width="70%" style=" ">
</object>
</div>
<div id="new-flow-of-information-3-magnify" class="magnify"
onclick="magnifyFigure(&#39;new-flow-of-information-3&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="new-flow-of-information-3-caption" class="caption-frame">
<p>Figure: The trinity of human, data, and computer, and highlights the
modern phenomenon. The communication channel between computer and data
now has an extremely high bandwidth. The channel between human and
computer and the channel between data and human is narrow. New direction
of information flow, information is reaching us mediated by the
computer. The focus on classical statistics reflected the importance of
the direct communication between human and data. The modern challenges
of data science emerge when that relationship is being mediated by the
machine.</p>
</div>
</div>
<p>Data science brings new challenges. In particular, there is a very
large bandwidth connection between the machine and data. This means that
our relationship with data is now commonly being mediated by the
machine. Whether this is in the acquisition of new data, which now
happens by happenstance rather than with purpose, or the interpretation
of that data where we are increasingly relying on machines to summarize
what the data contains. This is leading to the emerging field of data
science, which must not only deal with the same challenges that
mathematical statistics faced in tempering our tendency to over
interpret data but must also deal with the possibility that the machine
has either inadvertently or maliciously misrepresented the underlying
data.</p>
<h2 id="computer-conversations">Computer Conversations</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/conversation-computer.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/conversation-computer.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="anne-computer-conversation-6-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/r255/./slides/diagrams//anne-computer-conversation006.svg" width="80%" style=" ">
</object>
</div>
<div id="anne-computer-conversation-6-magnify" class="magnify"
onclick="magnifyFigure(&#39;anne-computer-conversation-6&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="anne-computer-conversation-6-caption" class="caption-frame">
<p>Figure: Conversation relies on internal models of other
individuals.</p>
</div>
</div>
<div class="figure">
<div id="anne-computer-conversation-8-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/r255/./slides/diagrams//anne-computer-conversation007.svg" width="80%" style=" ">
</object>
</div>
<div id="anne-computer-conversation-8-magnify" class="magnify"
onclick="magnifyFigure(&#39;anne-computer-conversation-8&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="anne-computer-conversation-8-caption" class="caption-frame">
<p>Figure: Misunderstanding of context and who we are talking to leads
to arguments.</p>
</div>
</div>
<p>Similarly, we find it difficult to comprehend how computers are
making decisions. Because they do so with more data than we can possibly
imagine.</p>
<p>In many respects, this is not a problem, it’s a good thing. Computers
and us are good at different things. But when we interact with a
computer, when it acts in a different way to us, we need to remember
why.</p>
<p>Just as the first step to getting along with other humans is
understanding other humans, so it needs to be with getting along with
our computers.</p>
<p>Embodiment factors explain why, at the same time, computers are so
impressive in simulating our weather, but so poor at predicting our
moods. Our complexity is greater than that of our weather, and each of
us is tuned to read and respond to one another.</p>
<p>Their intelligence is different. It is based on very large quantities
of data that we cannot absorb. Our computers don’t have a complex
internal model of who we are. They don’t understand the human condition.
They are not tuned to respond to us as we are to each other.</p>
<p>Embodiment factors encapsulate a profound thing about the nature of
humans. Our locked in intelligence means that we are striving to
communicate, so we put a lot of thought into what we’re communicating
with. And if we’re communicating with something complex, we naturally
anthropomorphize them.</p>
<p>We give our dogs, our cats, and our cars human motivations. We do the
same with our computers. We anthropomorphize them. We assume that they
have the same objectives as us and the same constraints. They don’t.</p>
<p>This means, that when we worry about artificial intelligence, we
worry about the wrong things. We fear computers that behave like more
powerful versions of ourselves that will struggle to outcompete us.</p>
<p>In reality, the challenge is that our computers cannot be human
enough. They cannot understand us with the depth we understand one
another. They drop below our cognitive radar and operate outside our
mental models.</p>
<p>The real danger is that computers don’t anthropomorphize. They’ll
make decisions in isolation from us without our supervision because they
can’t communicate truly and deeply with us.</p>
<h2 id="thanks">Thanks!</h2>
<p>For more information on these subjects and more you might want to
check the following resources.</p>
<ul>
<li>twitter: <a href="https://twitter.com/lawrennd">@lawrennd</a></li>
<li>podcast: <a href="http://thetalkingmachines.com">The Talking
Machines</a></li>
<li>newspaper: <a
href="http://www.theguardian.com/profile/neil-lawrence">Guardian Profile
Page</a></li>
<li>blog: <a
href="http://inverseprobability.com/blog.html">http://inverseprobability.com</a></li>
</ul>
<h1 class="unnumbered" id="references">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent"
role="list">
<div id="ref-Heider:interpersonal58" class="csl-entry" role="listitem">
Heider, F., 1958. The psychology of interpersonal relations. John Wiley.
</div>
<div id="ref-Lawrence:embodiment17" class="csl-entry" role="listitem">
Lawrence, N.D., 2017. <a href="https://arxiv.org/abs/1705.07996">Living
together: Mind and machine intelligence</a>. arXiv.
</div>
</div>

